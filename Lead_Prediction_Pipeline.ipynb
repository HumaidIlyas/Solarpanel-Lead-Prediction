{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "476a9dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import sklearn.linear_model\n",
    "import warnings\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import joblib\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "13b488cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Humaid Ilyas\\AppData\\Local\\Temp\\ipykernel_3800\\3624309559.py:1: DtypeWarning: Columns (3,14,23,25,26,27,58,59,60,61,64,65,66,67,68,69,70,71,72,73,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_leads = pd.read_csv('cluster_data.csv')\n"
     ]
    }
   ],
   "source": [
    "df_leads = pd.read_csv('cluster_data.csv')\n",
    "null_columns = list(df_leads.columns[df_leads.isna().all()])\n",
    "df_leads = df_leads.drop(columns=null_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "afe0b0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads.dropna(subset=[\"Cluster\"],inplace=True)\n",
    "df_leads = df_leads.replace(\"-\", pd.NA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f102bd5",
   "metadata": {},
   "source": [
    "##### Merging both the instances of \"Installation Partner Allocation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "861084a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads['Last Updated Stage'] = df_leads['Last Updated Stage'].replace(\"Installation partner Allocation\", \"Installation Partner Allocation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "63bd75ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_cases = ['Order Lost', 'Design Infeasible'] #Assign 0\n",
    "success = ['Site Survey'] #Assign 1\n",
    "process_phases = ['Lead Generation','Sales Partner Assignment','Communication'] #Don't Consider these phases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6280e57c",
   "metadata": {},
   "source": [
    "## Date Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "decd6fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_attributes = list(df_leads.filter(regex='creation date|deadline date', axis=1).columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03171cb6",
   "metadata": {},
   "source": [
    "## List of Phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "0a6ce0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "deadline_loss_phases = list(df_leads.filter(regex='cold_lead|design_infeasible|order_lost|deadline', axis=1).columns)\n",
    "all_phases = [item for item in date_attributes if item not in deadline_loss_phases]\n",
    "pre_survey_no_deadline = list(df_leads.filter(regex='lead_generation - deadline date|sales_partner_assignment - deadline date|communication - deadline date', axis=1).columns) #Phases that precede site survey\n",
    "post_survey_no_deadline = [item for item in date_attributes if item not in pre_survey_no_deadline]\n",
    "\n",
    "loss_reason = ['Cold Lead', 'Design Infeasible', 'Order Lost'] # All loss reasons\n",
    "loss_reason_timestamp = ['cold_lead - creation date','design_infeasible - creation date','order_lost - creation date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941565a4",
   "metadata": {},
   "source": [
    "##### Mapping the Last updated stage names to the columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "96b8aa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Lead Generation': 'lead_generation - creation date', 'Communication': 'communication - creation date', 'Sales Partner Assignment': 'sales_partner_assignment - creation date', 'Cold Lead': 'cold_lead - creation date', 'Technical Design Assessment': 'technical_design_assessment - creation date', 'Proposal': 'proposal - creation date', 'Order Lost': 'order_lost - creation date', 'Design & Material Planning': 'design_&_material_planning - creation date', 'Installation Partner Allocation': 'installation_partner_allocation - creation date', 'New Project': 'new_project - creation date', 'Site Survey': 'site_survey - creation date', 'Material Dispatch': 'material_dispatch - creation date', 'DISCOM NOC Received': 'discom_noc_received - creation date', 'Final Commercial': 'final_commercial - creation date', 'Material Received at Site': 'material_received_at_site - creation date', 'Net Metering Application': 'net_metering_application - creation date', 'Customer KYC Verification': 'customer_kyc_verification - creation date', 'Meter Installation': 'meter_installation - creation date', 'Customer KYC': 'customer_kyc - creation date', 'Design Infeasible': 'design_infeasible - creation date', 'Logger Data Configuration': 'logger_data_configuration - creation date', 'Site QC': 'site_qc - creation date', 'Application Form Upload': 'application_form_upload - creation date', 'Site Commissioned': 'site_commissioned - creation date', 'Installation': 'installation - creation date'}\n"
     ]
    }
   ],
   "source": [
    "def convert_phase_name(phase_name):\n",
    "    \"\"\"Convert a phase name to its corresponding format in 'Preceding Phase' column.\"\"\"\n",
    "    converted_name = phase_name.replace(\" \", \"_\").lower() + \" - creation date\"\n",
    "    return converted_name\n",
    "\n",
    "def create_mapping_dict(phase_list):\n",
    "    \"\"\"Create a mapping dictionary from a list of phase names.\"\"\"\n",
    "    mapping_dict = {phase: convert_phase_name(phase) for phase in phase_list}\n",
    "    return mapping_dict\n",
    "\n",
    "# Use the function to create the mapping dictionary \n",
    "mapping_dict = create_mapping_dict(list(df_leads['Last Updated Stage'].unique()))\n",
    "print(mapping_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357543c9",
   "metadata": {},
   "source": [
    "## Converting to DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ca178217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Humaid Ilyas\\AppData\\Local\\Temp\\ipykernel_3800\\1610420508.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_leads[date_attributes] = df_leads[date_attributes].applymap(lambda x: pd.to_datetime(x))\n",
      "C:\\Users\\Humaid Ilyas\\AppData\\Local\\Temp\\ipykernel_3800\\1610420508.py:2: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_leads[['Last Updated On','Created On']] = df_leads[['Last Updated On','Created On']].applymap(lambda x: pd.to_datetime(x))\n"
     ]
    }
   ],
   "source": [
    "df_leads[date_attributes] = df_leads[date_attributes].applymap(lambda x: pd.to_datetime(x))\n",
    "df_leads[['Last Updated On','Created On']] = df_leads[['Last Updated On','Created On']].applymap(lambda x: pd.to_datetime(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b66261",
   "metadata": {},
   "source": [
    "## Get phases in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "067839b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lead_generation - creation date',\n",
       " 'sales_partner_assignment - creation date',\n",
       " 'communication - creation date',\n",
       " 'site_survey - creation date',\n",
       " 'technical_assessment - creation date',\n",
       " 'proposal - creation date',\n",
       " 'final_commercial - creation date',\n",
       " 'customer_kyc - creation date',\n",
       " 'kyc_verification - creation date',\n",
       " 'net_metering_application - creation date',\n",
       " 'design_and_material_planning - creation date',\n",
       " 'discom_noc_received - creation date',\n",
       " 'installation_partner_allocation - creation date',\n",
       " 'material_dispatch - creation date',\n",
       " 'material_received_at_site - creation date',\n",
       " 'installation - creation date',\n",
       " 'site_qc - creation date',\n",
       " 'meter_installation - creation date',\n",
       " 'logger_data_config - creation date',\n",
       " 'site_commissioned - creation date']"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def move_to_index(lst, target, index):\n",
    "    \"\"\"Move target element in lst to the specified index.\"\"\"\n",
    "    if target in lst:\n",
    "        lst.remove(target)\n",
    "        lst.insert(index, target)\n",
    "    return lst\n",
    "\n",
    "move_to_index(post_survey_no_deadline, 'technical_assessment - creation date', 1)\n",
    "move_to_index(all_phases, 'technical_assessment - creation date', 4)\n",
    "move_to_index(all_phases, 'sales_partner_assignment - creation date', 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f4e66",
   "metadata": {},
   "source": [
    "## Function for preceding phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "8700deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary mapping loss reasons to their timestamp columns\n",
    "loss_reason_to_timestamp = dict(zip(loss_reason, loss_reason_timestamp))\n",
    "\n",
    "def get_preceding_phase(row):\n",
    "    if row['Last Updated Stage'] in loss_reason:\n",
    "        loss_timestamp_col = loss_reason_to_timestamp[row['Last Updated Stage']]\n",
    "        loss_timestamp = pd.Timestamp(row[loss_timestamp_col])\n",
    "        \n",
    "        # Filter out the phase columns only and drop the NaNs\n",
    "        phase_timestamps = row[all_phases].dropna()   #Just change this to pre_survey_no_deadline \n",
    "        \n",
    "        # Get the most recent phase timestamp just before the loss timestamp\n",
    "        preceding_phase_timestamp = max([ts for ts in phase_timestamps if pd.Timestamp(ts) < loss_timestamp], default=None)\n",
    "        \n",
    "        if preceding_phase_timestamp:\n",
    "            return phase_timestamps[phase_timestamps == preceding_phase_timestamp].index[0]\n",
    "    return None\n",
    "\n",
    "df_leads['Preceding Phase'] = df_leads.apply(get_preceding_phase, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b95fe91",
   "metadata": {},
   "source": [
    "# Creating the Target Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "7fcfbdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe for rows where 'Last Updated Stage' is 'Cold Lead'\n",
    "# Get the 'Preceding Phase' column values for these rows\n",
    "cold_lead_preceding_phases = df_leads[df_leads['Last Updated Stage'] == 'Cold Lead']['Preceding Phase']\n",
    "dead_lead_preceding_phases = df_leads[df_leads['Last Updated Stage'].isin(['Order Lost', 'Design Infeasible'])]['Preceding Phase']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86a149",
   "metadata": {},
   "source": [
    "## Assign Dead Leads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "546d697f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Humaid Ilyas\\AppData\\Local\\Temp\\ipykernel_3800\\563708358.py:18: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'Dead' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_leads.loc[relevant_dead_indices, 'Target'] = 'Dead'\n"
     ]
    }
   ],
   "source": [
    "# Filter the original dataframe using the conditions of dead_lead_preceding_phases\n",
    "dead_lead_rows = df_leads[df_leads['Last Updated Stage'].isin([\"Order Lost\", \"Design Infeasible\"])]\n",
    "\n",
    "# Get value counts of dead_lead_preceding_phases\n",
    "dead_lead_counts_pre = dead_lead_preceding_phases.value_counts()\n",
    "\n",
    "# Filter counts based on the mapped names from survey_onwards_phases\n",
    "pre_dead_leads = dead_lead_counts_pre[dead_lead_counts_pre.index.isin(mapping_dict.values())]\n",
    "\n",
    "# Filter the rows based on post_dead_leads criteria using the mapping_dict\n",
    "relevant_dead_rows = dead_lead_rows[dead_lead_rows['Preceding Phase'].isin(pre_dead_leads.index)]\n",
    "\n",
    "# Capture the indices of these rows\n",
    "relevant_dead_indices = relevant_dead_rows.index\n",
    "\n",
    "\n",
    "# Use dead_indices to set the 'Target' value to 'Dead' in the original dataframe\n",
    "df_leads.loc[relevant_dead_indices, 'Target'] = 'Dead'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a415c3",
   "metadata": {},
   "source": [
    "## Assign Colds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "310667dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the mapping function and phase list are already defined:\n",
    "mapping_dict = create_mapping_dict(['Lead Generation', 'Communication', 'Sales Partner Assignment'])\n",
    "\n",
    "# Get value counts of cold_lead_preceding_phases\n",
    "cold_lead_counts_pre = cold_lead_preceding_phases.value_counts()\n",
    "\n",
    "# Filter counts based on the mapped names from survey_onwards_phases\n",
    "pre_cold_leads = cold_lead_counts_pre[cold_lead_counts_pre.index.isin(mapping_dict.values())]\n",
    "\n",
    "# Filter the original dataframe using the conditions of cold_lead_preceding_phases\n",
    "cold_lead_rows = df_leads[df_leads['Last Updated Stage'] == \"Cold Lead\"]\n",
    "\n",
    "# Filter the rows based on post_cold_leads criteria using the mapping_dict\n",
    "relevant_cold_rows = cold_lead_rows[cold_lead_rows['Preceding Phase'].isin(pre_cold_leads.index)]\n",
    "\n",
    "# Capture the indices of these rows\n",
    "relevant_cold_indices = relevant_cold_rows.index\n",
    "\n",
    "\n",
    "# Use cold_indices to set the 'Target' value to 'Cold' in the original dataframe\n",
    "df_leads.loc[relevant_cold_indices, 'Target'] = 'Cold'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "c358eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_phases = ['Lead Generation',\n",
    " 'Sales Partner Assignment',\n",
    " 'Communication',\n",
    " 'Site Survey',\n",
    " 'Cold Lead',\n",
    " 'Design Infeasible',\n",
    " 'Order Lost']\n",
    "phases = list(df_leads['Last Updated Stage'].unique())\n",
    "post_survey_process = [phase for phase in phases if phase not in relevant_phases]\n",
    "post_survey_process = post_survey_process + [\"Site Survey\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb46a93a",
   "metadata": {},
   "source": [
    "## Colds as Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "b752ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the mapping function and phase list are already defined:\n",
    "mapping_dict = create_mapping_dict(post_survey_process)\n",
    "\n",
    "# Get value counts of cold_lead_preceding_phases\n",
    "cold_lead_counts_post = cold_lead_preceding_phases.value_counts()\n",
    "\n",
    "# Filter counts based on the mapped names from survey_onwards_phases\n",
    "post_cold_leads = cold_lead_counts_post[cold_lead_counts_post.index.isin(mapping_dict.values())]\n",
    "\n",
    "# print(post_cold_leads)\n",
    "### Assign Colds\n",
    "# Filter the original dataframe using the conditions of cold_lead_preceding_phases\n",
    "cold_lead_rows = df_leads[df_leads['Last Updated Stage'] == \"Cold Lead\"]\n",
    "\n",
    "# Filter the rows based on post_cold_leads criteria using the mapping_dict\n",
    "relevant_cold_rows = cold_lead_rows[cold_lead_rows['Preceding Phase'].isin(post_cold_leads.index)]\n",
    "\n",
    "# Capture the indices of these rows\n",
    "relevant_cold_indices = relevant_cold_rows.index\n",
    "\n",
    "\n",
    "# Use cold_indices to set the 'Target' value to 'Cold' in the original dataframe\n",
    "df_leads.loc[relevant_cold_indices, 'Target'] = 'Success'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d60fa61",
   "metadata": {},
   "source": [
    "## Deads as Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "d89f482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming you already have the mapping function and the phase list:\n",
    "mapping_dict = create_mapping_dict(post_survey_process)\n",
    "\n",
    "# Get value counts of dead_lead_preceding_phases\n",
    "dead_lead_counts_post = dead_lead_preceding_phases.value_counts()\n",
    "\n",
    "# Filter counts based on the mapped names from survey_onwards_phases\n",
    "post_dead_leads = dead_lead_counts_post[dead_lead_counts_post.index.isin(mapping_dict.values())]\n",
    "\n",
    "# print(post_dead_leads)\n",
    "### Assign as Colds\n",
    "\n",
    "# Filter the original dataframe using the conditions of dead_lead_preceding_phases\n",
    "dead_lead_rows = df_leads[df_leads['Last Updated Stage'].isin([\"Order Lost\", \"Design Infeasible\"])]\n",
    "\n",
    "# Get value counts of dead_lead_preceding_phases\n",
    "dead_lead_counts_post = dead_lead_preceding_phases.value_counts()\n",
    "\n",
    "# Filter counts based on the mapped names from survey_onwards_phases\n",
    "post_dead_leads = dead_lead_counts_post[dead_lead_counts_post.index.isin(mapping_dict.values())]\n",
    "\n",
    "# Filter the rows based on post_dead_leads criteria using the mapping_dict\n",
    "relevant_dead_rows = dead_lead_rows[dead_lead_rows['Preceding Phase'].isin(post_dead_leads.index)]\n",
    "\n",
    "# Capture the indices of these rows\n",
    "relevant_dead_indices = relevant_dead_rows.index\n",
    "\n",
    "\n",
    "\n",
    "# Use dead_indices to set the 'Target' value to 'Dead' in the original dataframe\n",
    "df_leads.loc[relevant_dead_indices, 'Target'] = 'Success'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1af90ae",
   "metadata": {},
   "source": [
    "## Post Survey processes as Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "7a01d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where 'Last Updated Stage' is in process_phases list\n",
    "condition_in_process = df_leads['Last Updated Stage'].isin(post_survey_process)\n",
    "\n",
    "# Update 'Target' column based on the condition\n",
    "df_leads.loc[condition_in_process, 'Target'] = 'Success'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f58df38",
   "metadata": {},
   "source": [
    "## In-Process Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "946f2994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where 'Last Updated Stage' is in process_phases list\n",
    "condition_in_process = df_leads['Last Updated Stage'].isin(['Lead Generation', 'Sales Partner Assignment', 'Communication'])\n",
    "\n",
    "# Update 'Target' column based on the condition\n",
    "df_leads.loc[condition_in_process, 'Target'] = 'in-process'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "b609bd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "Cold          12702\n",
       "in-process     6959\n",
       "Success        1280\n",
       "Dead            915\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_leads[\"Target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d04eaef",
   "metadata": {},
   "source": [
    "## Drop the cold entries, Assign 1 to Success and 0 to others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "e8a5be10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Humaid Ilyas\\AppData\\Local\\Temp\\ipykernel_3800\\707154973.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_leads[\"Target\"] = df_leads[\"Target\"].map({'Success': 1, 'in-process': 0, 'Dead': 0})\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where 'Target' is 'Cold'\n",
    "df_leads = df_leads[df_leads[\"Target\"] != 'Cold']\n",
    "\n",
    "# Map 'Success' to 1 and all other values to 0\n",
    "df_leads[\"Target\"] = df_leads[\"Target\"].map({'Success': 1, 'in-process': 0, 'Dead': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "55dcfbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "0.0    7874\n",
       "1.0    1280\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_leads[\"Target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e2f70c",
   "metadata": {},
   "source": [
    "## Get Lead to Comm time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "73ef7e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Humaid Ilyas\\AppData\\Local\\Temp\\ipykernel_3800\\3864726942.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_leads['lead to comm time'] = (df_leads['communication - creation date'] - df_leads['lead_generation - creation date']).dt.days\n"
     ]
    }
   ],
   "source": [
    "# Assuming both columns are already in datetime format\n",
    "df_leads['lead to comm time'] = (df_leads['communication - creation date'] - df_leads['lead_generation - creation date']).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92be4337",
   "metadata": {},
   "source": [
    "## Making City Tiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "b075fb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Humaid Ilyas\\AppData\\Local\\Temp\\ipykernel_3800\\4247914309.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_leads['City'].replace(city_merge_dict, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Define a mapping dictionary for cities to be merged\n",
    "city_merge_dict = {\n",
    "    'Allahabad': 'Prayagraj/Allahabad',\n",
    "    'Prayagraj': 'Prayagraj/Allahabad',\n",
    "    'Bengaluru': 'Bengaluru/ Bangalore',\n",
    "    'Bangalore': 'Bengaluru/ Bangalore',\n",
    "    'Delhi': 'Delhi_NCR',\n",
    "    'New Delhi': 'Delhi_NCR',\n",
    "}\n",
    "\n",
    "# Replace city names in the 'City' column based on the dictionary\n",
    "df_leads['City'].replace(city_merge_dict, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "5f2af253",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tier1_cities =  ['Ahmedabad', 'Bengaluru', 'Bangalore', 'Chennai', 'Delhi', 'Hyderabad', 'Kolkata', 'Mumbai', 'Pune']\n",
    "Tier2_cities =  [\"Agra\", \"Ajmer\", \"Aligarh\", \"Amravati\", \"Amritsar\", \"Anand\", \"Asansol\", \"Aurangabad\", \"Bareilly\", \"Belagavi\",\n",
    "                  \"Brahmapur\", \"Bhavnagar\", \"Bhiwandi\", \"Bhopal\", \"Bhubaneswar\", \"Bikaner\", \"Bilaspur\", \"Bokaro Steel City\", \"Burdwan\", \n",
    "                  \"Chandigarh\", \"Coimbatore\", \"Cuttack\", \"Dahod\", \"Dehradun\", \"Dombivli\", \"Dhanbad\", \"Bhilai\", \"Durgapur\", \"Erode\", \"Faridabad\", \"Ghaziabad\", \"Gorakhpur\", \"Guntur\", \"Gurgaon\",\"Gurugram\", \"Guwahati\", \"Gwalior\", \"Hamirpur\", \"Hubballi–Dharwad\", \"Indore\", \"Jabalpur\", \"Jaipur\", \"Jalandhar\", \"Jalgaon\", \"Jammu\", \n",
    "                 \"Jamshedpur\", \"Jhansi\", \"Jodhpur\", \"Kalaburagi\", \"Kakinada\", \"Kannur\", \"Kanpur\", \"Karnal\", \"Kochi\", \"Kolhapur\", \"Kollam\", \"Kota\", \"Kozhikode\", \"Kumbakonam\", \"Kurnool\", \"Ludhiana\", \"Lucknow\", \"Madurai\", \"Malappuram\", \"Mathura\", \"Mangaluru\", \"Meerut\", \"Moradabad\", \"Mysuru\", \"Nagpur\", \"Nanded\", \"Nadiad\", \"Nashik\", \"Nellore\", \"Noida\", \"Patna\", \"Puducherry\", \"Purulia\", \"Prayagraj\", \"Raipur\", \"Rajkot\", \"Rajamahendravaram\", \"Ranchi\", \"Rourkela\", \"Ratlam\", \"Saharanpur\", \"Salem\", \"Sangli\", \"Shimla\", \"Siliguri\", \"Solapur\", \"Srinagar\", \"Surat\", \"Thanjavur\", \"Thiruvananthapuram\", \"Thrissur\", \"Tiruchirappalli\", \"Tirunelveli\", \"Tiruvannamalai\", \"Ujjain\", \"Vijayapura\", \"Vadodara\", \"Varanasi\", \"Vasai-Virar\", \"Vijayawada\", \"Visakhapatnam\", \"Vellore\", \"Warangal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "6dc58387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Humaid Ilyas\\AppData\\Local\\Temp\\ipykernel_3800\\2507724482.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_leads['City Tier'] = df_leads['City'].apply(assign_tier)\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "\n",
    "def assign_tier(city):\n",
    "    # Convert the city to a string\n",
    "    city = str(city)\n",
    "    \n",
    "    # Check match with Tier 1 cities\n",
    "    if process.extractOne(city, Tier1_cities)[1] >= 85:\n",
    "        return 3\n",
    "    # Check match with Tier 2 cities\n",
    "    elif process.extractOne(city, Tier2_cities)[1] >= 85:\n",
    "        return 2\n",
    "    # If not a match in either, assign Tier 3\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "df_leads['City Tier'] = df_leads['City'].apply(assign_tier)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d1e7f5",
   "metadata": {},
   "source": [
    "## Source Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "893ae6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_merge = {\n",
    "'inhouse website': ['gethomescaped', 'website', 'ampluswebsite', 'contactuspage', 'homescapecontactform', 'atriuminviteform'],\n",
    "'offline': ['karkardoomakarkardooma', 'suncitysolarmelasuncitysolarmela', 'soalrisesafdargunjsoalrisesafdargunj', 'safdargunjsafdargunj', 'broadsolarhyd', 'broadsolardelhi', 'delhigolfclub', 'keralaexpo', 'acconevent', 'karnalfair', 'tataddl', 'malaysianembassy', 'chdexpo', 'patioclub', 'database'],\n",
    "'astral': ['astral'],\n",
    "'ivr': ['ivr', 'freshchat+ivr', 'ivrfranchisepartner'],\n",
    "'freshchat': ['freshchat'],\n",
    "'mail': ['mail', 'utmsource=gmaildisplay,utmmedium=gmail,utmcampaign=leadsgmail28052021', 'utmsource=email,utmmedium=sitevisit,utmcampaign=edm1'],\n",
    "'fb or google': ['lookalikeleadhssep2022', 'lookalikecampaign', 'campaign', 'landingpagegoa', 'landingpagegoogle', 'landingpagefacebook', 'landingpage1', 'landingpage2','landingpage3', 'newlandingpage', 'landingpagefb'],\n",
    "'fb': ['facebooknewyearoffer2021', 'fbhomescapebyamplusleadgeneration', 'fbad3homescapebyamplusleadgeneration', 'fbad1chdleadgenerationrealproductad', 'facebook', 'facebookmessenger', 'facebookleadgenform1', 'facebookremarketing', 'fbad6ncrleadgen', 'fbad6chdleadgen', 'fbad6leadgen'],\n",
    "'app': ['app'],\n",
    "'customerapp': ['customerapp'],\n",
    "'partnerapp': ['partnerapp'],\n",
    "'whatsapp': ['whatsapp'],\n",
    "'franchise': ['franchise'],\n",
    "'reference': ['reference'],\n",
    "'': [''],\n",
    "'referral': ['referral'],\n",
    "'channelpartner': ['channelpartner'],\n",
    "'salespartner': ['salespartner'],\n",
    "'housing': ['housing', 'housing2'],\n",
    "'bses': ['bses', 'bseslead'],\n",
    "'acetech': ['acetech'],\n",
    "'linkedin': ['linkedin'],\n",
    "'mygate': ['mygatemay2022'],\n",
    "'third party': ['btl', 'ziffy', 'smscold1'],\n",
    "  'default': ['default'],\n",
    "  'justdial': ['justdial'],\n",
    "'source=solarpanels2': ['source=solarpanels2'],\n",
    "  'google': ['googlebusiness', 'utmsource=bingsearch,utmmedium=bing,utmcampaign=searchdelhihary14062021'],\n",
    "'displayresponsive': ['displayresponsive', 'utmsource=displayresponsive,utmmedium=exclusivedesign,utmcampaign='],\n",
    "'magicbricks': ['magicbricks'],\n",
    "'instagram': ['igad5whatami', 'ighomescapebyamplusleadgeneration', 'igad6leadgen', 'igad6chdleadgen', 'igad6ncrleadgen', 'igad1chdleadgenerationrealproductad', 'igad3homescapebyamplusleadgeneration', ],\n",
    "'hubspot': ['hubspot'],\n",
    "'gujratleadupload': ['gujratleadupload'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "3ba8baaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Humaid Ilyas\\AppData\\Local\\Temp\\ipykernel_3800\\3008395188.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_leads['Source'] = df_leads['Source'].str.lower().str.replace(' ', '')\n",
      "C:\\Users\\Humaid Ilyas\\AppData\\Local\\Temp\\ipykernel_3800\\3008395188.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_leads['Source'] = df_leads['Source'].apply(replace_with_mapping)\n"
     ]
    }
   ],
   "source": [
    "# Convert all keys and values in the source_merge dictionary to lowercase and remove spaces\n",
    "source_merge = {k.lower().replace(\" \", \"\"): [x.lower().replace(\" \", \"\") for x in v] for k, v in source_merge.items()}\n",
    "\n",
    "# Convert the values in the 'Source' column to lowercase and remove spaces\n",
    "df_leads['Source'] = df_leads['Source'].str.lower().str.replace(' ', '')\n",
    "\n",
    "# Function to replace values based on the source_merge dictionary\n",
    "def replace_with_mapping(value):\n",
    "    for key, values_list in source_merge.items():\n",
    "        if value in values_list:\n",
    "            return key\n",
    "    return value\n",
    "\n",
    "# Apply the replacement function to the 'Source' column\n",
    "df_leads['Source'] = df_leads['Source'].apply(replace_with_mapping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe437f8b",
   "metadata": {},
   "source": [
    "# Form Name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "80a36247",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_frequency = df_leads.groupby(['Form Name', 'Source']).size().reset_index(name='Count')\n",
    "pair_frequency = pair_frequency.sort_values(by='Count', ascending=False)\n",
    "unique_sources = pair_frequency['Source'].unique()\n",
    "null_form_name_pairs = df_leads[df_leads['Form Name'].isnull()].groupby('Source').size().reset_index(name='Count')\n",
    "unique_null_sources = null_form_name_pairs['Source'].unique()\n",
    "common_sources = list(set(unique_null_sources) & set(unique_sources))\n",
    "no_form_sources = list(set(unique_null_sources) - set(common_sources)) #Sources which don't require forms\n",
    "all_sources = list(df_leads['Source'].unique())\n",
    "on_form_sum = no_form_sources + common_sources\n",
    "only_form_sources = list(set(all_sources) - set(on_form_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "589b9173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the rows where 'Form Name' is null and 'Source' matches any value in no_form_sources\n",
    "condition = (df_leads['Form Name'].isnull()) & (df_leads['Source'].isin(no_form_sources))\n",
    "\n",
    "# Replace null values in 'Form Name' for those rows with 'Other'\n",
    "df_leads.loc[condition, 'Form Name'] = 'Other'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff3bf4a",
   "metadata": {},
   "source": [
    "## Cleaning Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "b7416f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a mask to replace the rest of india category\n",
    "mask = (df_leads['Cluster'] == \"Rest_of_India\") & (df_leads['State.1'].notnull())\n",
    "df_leads.loc[mask, 'Cluster'] = df_leads.loc[mask, 'State.1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c392675",
   "metadata": {},
   "source": [
    "## Dealing with null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "920aa9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_leads = df_leads.dropna(subset=['Target'])\n",
    "\n",
    "mode_value = df_leads['Source'].mode()[0]\n",
    "mode_city = df_leads['City Tier'].mode()[0]\n",
    "df_leads['Source'].fillna(mode_value, inplace=True)\n",
    "df_leads['Form Name'].fillna(\"No_Form\", inplace=True)\n",
    "df_leads['City Tier'].fillna(mode_city, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "170a3f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_leads['lead to comm time'] = df_leads['lead to comm time'].fillna(df_leads['lead to comm time'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96138f5a",
   "metadata": {},
   "source": [
    "## Selecting the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "ca1b85cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting specified columns\n",
    "selected_columns = ['Source', 'Cluster', 'Lead Category', 'Form Name', 'City Tier', 'Target', 'lead to comm time']\n",
    "\n",
    "# Creating the new DataFrame df_clean with the selected columns\n",
    "df_clean = df_leads[selected_columns].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51eb679",
   "metadata": {},
   "source": [
    "# MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "00359a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df_clean, columns=['Source', 'Cluster', 'Lead Category', 'Form Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354e71fd",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "5bdb2c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_encoded.copy()\n",
    "features = features.drop(['Target'], axis=1)\n",
    "target = df_encoded[['Target']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42, stratify = target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac72aef",
   "metadata": {},
   "source": [
    "## Validation Split and SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "84f09225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a validation set from the training data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "dea26d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Humaid Ilyas\\1\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier(random_state=42)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model with SMOTE-enhanced data\n",
    "gb_model_smote = GradientBoostingClassifier(random_state=42)\n",
    "gb_model_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Save the model to a file\n",
    "# joblib.dump(gb_model_smote, 'gb_model_smote.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1390cb59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
